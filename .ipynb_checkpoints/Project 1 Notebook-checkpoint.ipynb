{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "N_KEYWORDS= 500\n",
    "N_VENUES = 470\n",
    "N_AUTHORS = 2302\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data sample:\n",
      "{'venue': '', 'keywords': [64, 1, 322, 134, 136, 396, 270, 144, 476, 481, 165, 39, 361, 43, 177, 308, 310, 118, 187, 127], 'year': 2017, 'author': [1605, 759]}\n",
      "\n",
      "Test data sample:\n",
      "{'venue': '', 'keywords': [260, 6, 390, 136, 7, 11, 17, 285, 288, 162, 422, 179, 55, 184, 61, 318, 451, 199, 457, 329, 459, 79, 469, 342, 213, 346, 474, 477, 478, 228, 230, 363, 494, 496, 241, 370, 378], 'year': 2017, 'coauthor': [], 'target': 988}\n"
     ]
    }
   ],
   "source": [
    "with open(\"train.json\") as f:\n",
    "    data = json.load(f)\n",
    "with open(\"test.json\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(\"Training data sample:\")\n",
    "print(data[\"0\"])\n",
    "print(\"\\nTest data sample:\")\n",
    "print(test_data[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of authors for any one paper: 9\n",
      "Max number of keywords for any one paper: 109\n",
      "Min number of authors for any one paper: 1\n",
      "Min number of keywords for any one paper: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def split_data(data, val_set_ratio = 0.2):\n",
    "    \"\"\"\n",
    "    Splits provided data into a training set and validation set\n",
    "    Validation set size proportion depends on val_set_ratio, anything not in the validation set is put into training\n",
    "    \"\"\"\n",
    "    keys = [key for key in data.keys()]\n",
    "    # calculate number of instances for validation set and take a random sample\n",
    "    val_set_size = int(val_set_ratio * len(keys))\n",
    "    val_keys = random.sample(keys, val_set_size)\n",
    "    val_data = {}\n",
    "    train_data = {}\n",
    "    # split between validation and training\n",
    "    for key in keys:\n",
    "        if key in val_keys:\n",
    "            val_data[key] = data[key]\n",
    "        else:\n",
    "            train_data[key] = data[key]\n",
    "    return train_data, val_data\n",
    "\n",
    "train_data, val_data = split_data(data)\n",
    "\n",
    "# find the max number of authors/keywords for any one paper in the data set\n",
    "author_counts = []\n",
    "keyword_counts = []\n",
    "for key in train_data:\n",
    "    author_counts.append(len(train_data[key]['author']))\n",
    "    keyword_counts.append(len(train_data[key]['keywords']))\n",
    "\n",
    "max_authors, min_authors = max(author_counts), min(author_counts)\n",
    "max_keywords, min_keywords = max(keyword_counts), min(keyword_counts)\n",
    "print(\"Max number of authors for any one paper:\", max_authors)\n",
    "print(\"Max number of keywords for any one paper:\", max_keywords)\n",
    "print(\"Min number of authors for any one paper:\", min_authors)\n",
    "print(\"Min number of keywords for any one paper:\", min_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coauthor_matrix(train_data):\n",
    "    \"\"\"\n",
    "    Returns a matrix (2D list) of how many papers each author has written \n",
    "    with each other author\n",
    "    \"\"\"\n",
    "    coauthor_matrix = [[0 for i in range(N_AUTHORS)] for j in range(N_AUTHORS)]\n",
    "    for key in train_data:\n",
    "        authors = train_data[key]['author']\n",
    "        for author1 in authors:\n",
    "            for author2 in authors:\n",
    "                coauthor_matrix[author1][author2] += 1\n",
    "    return coauthor_matrix\n",
    "\n",
    "def get_keyword_matrix(train_data):\n",
    "    \"\"\"\n",
    "    Returns a matrix (2D list) of how many papers each author has written \n",
    "    that has each keyword\n",
    "    \"\"\"\n",
    "    keyword_matrix = [[0 for i in range(N_KEYWORDS)] for j in range(N_AUTHORS)]\n",
    "    for key in train_data:\n",
    "        keywords = train_data[key]['keywords']\n",
    "        authors = train_data[key]['author']\n",
    "        for author in authors:\n",
    "            for keyword in keywords:\n",
    "                keyword_matrix[author][keyword] += 1\n",
    "    return keyword_matrix\n",
    "\n",
    "def pad(data_list, n, val):\n",
    "    \"\"\"\n",
    "    Pads data_list with val until it is of length n\n",
    "    If len(data_list) > n, cuts the list so that it is of length n\n",
    "    \"\"\"\n",
    "    n_missing = n - len(data_list)\n",
    "    if n_missing < 0:\n",
    "        return data_list[:n]\n",
    "    return data_list + n_missing*[val]\n",
    "\n",
    "ca_matrix = get_coauthor_matrix(train_data)\n",
    "kw_matrix = get_keyword_matrix(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(train_data, coauthor_matrix=[], keyword_matrix = []):\n",
    "    \"\"\"\n",
    "    Takes each entry in training data and creates a new entry for each author of the form:\n",
    "    year, keyword_0, keyword_1, ..., keyword_499, coauthor_0, coauthor_1, ... coauthor_499, target\n",
    "    where target is an int in the range [0, 2301] and keyword_x and coauthor_x is in {0, 1} depending on if the \n",
    "    keyword/coauthor is in the entry\n",
    "    Eg. Entry = {venue: '', keywords: [0, 3], year: 2011, author: [1, 2]} becomes the following entries:\n",
    "    [2011,     1, 0, 0, 1, 0, 0, ..., 0,     0, 0, 1, 0, 0, ..., 0,     1]\n",
    "    [2011,     1, 0, 0, 1, 0, 0, ..., 0,     0, 1, 0, 0, 0, ..., 0,     2]\n",
    "     year     |        keywords        |    |     coauthors       |   target\n",
    "    \"\"\"\n",
    "    train_data_processed = []\n",
    "    \n",
    "    for key in train_data:\n",
    "        # ignores venue at the moment since papers with no venue will all be treated the same which maybe we do not want?\n",
    "        # venue = entry['venue']\n",
    "        entry = train_data[key]\n",
    "        keywords = entry['keywords']\n",
    "        year = entry['year']\n",
    "        authors = entry['author']\n",
    "        \n",
    "        # converts keywords into a binary representation\n",
    "        # TODO: find a simpler way to represent (currently given as an array of length 500)\n",
    "        keyword_list = [1 if i in keywords else 0 for i in range(N_KEYWORDS)]\n",
    "        \n",
    "        for i in range(len(authors)):\n",
    "            target = authors[i]\n",
    "            \n",
    "            # sorts keywords based on the most common keyword associated with the target\n",
    "            if keyword_matrix:\n",
    "                keyword_list = sorted(\n",
    "                    keywords, \n",
    "                    key=lambda x: keyword_matrix[target][x]\n",
    "                )\n",
    "                keyword_list = pad(keyword_list, max_keywords, keyword_list[0])\n",
    "            \n",
    "            # takes all authors other than the target as coauthors\n",
    "            coauthor = [author for author in authors if author != target]\n",
    "            \n",
    "            # sorts coauthors based on the most common author who has written with the target\n",
    "            if coauthor_matrix:\n",
    "                coauthor = sorted(\n",
    "                    coauthor, \n",
    "                    key=lambda x: coauthor_matrix[target][x]\n",
    "                )\n",
    "                coauthor = pad(coauthor, max_authors, target)\n",
    "            else:\n",
    "                # converts coauthors into a binary representation\n",
    "                # TODO: find a simpler way to represent (currently given as an array of length 2302)\n",
    "                coauthor = [1 if i in coauthor else 0 for i in range(N_AUTHORS)]\n",
    "            \n",
    "            # concatenate everything and append to processed list\n",
    "            train_data_processed.append([year] + keyword_list + coauthor + [target])\n",
    "    \n",
    "    return train_data_processed\n",
    "\n",
    "def process_data_test(test_data, coauthor_matrix=[], keyword_matrix = []):\n",
    "    \"\"\"\n",
    "    same as above but for the provided test data\n",
    "    \"\"\"\n",
    "    test_data_processed = []\n",
    "    \n",
    "    for key in test_data:\n",
    "        # ignores venue at the moment since papers with no venue will all be treated the same which maybe we do not want?\n",
    "        # venue = entry['venue']\n",
    "        entry = test_data[key]\n",
    "        keywords = entry['keywords']\n",
    "        year = entry['year']\n",
    "        coauthor = entry['coauthor']\n",
    "        target = entry['target']\n",
    "        \n",
    "        # converts keywords into a binary representation\n",
    "        # TODO: find a simpler way to represent (currently given as an array of length 500)\n",
    "        keyword_list = [1 if i in keywords else 0 for i in range(N_KEYWORDS)]\n",
    "            \n",
    "        # sorts keywords based on the most common keyword associated with the target\n",
    "        if keyword_matrix:\n",
    "            keyword_list = sorted(\n",
    "                keywords, \n",
    "                key=lambda x: keyword_matrix[target][x]\n",
    "            )\n",
    "            keyword_list = pad(keyword_list, max_keywords, keyword_list[0])\n",
    "            \n",
    "        # sorts coauthors based on the most common author who has written with the target\n",
    "        if coauthor_matrix:\n",
    "            coauthor = sorted(\n",
    "                coauthor, \n",
    "                key=lambda x: coauthor_matrix[target][x]\n",
    "            )\n",
    "            coauthor = pad(coauthor, max_authors, target)\n",
    "        else:\n",
    "            # converts coauthors into a binary representation\n",
    "            # TODO: find a simpler way to represent (currently given as an array of length 2302)                coauthor = [1 if i in coauthor else 0 for i in range(N_AUTHORS)]\n",
    "            coauthor = [1 if i in coauthor else 0 for i in range(N_AUTHORS)]\n",
    "            \n",
    "        # concatenate everything and append to processed list\n",
    "        test_data_processed.append([year] + keyword_list + coauthor + [target])\n",
    "    \n",
    "    return test_data_processed\n",
    "\n",
    "# process data\n",
    "train_data_processed = process_data(\n",
    "    train_data, \n",
    "    coauthor_matrix=ca_matrix, \n",
    "    keyword_matrix=kw_matrix\n",
    ")\n",
    "val_data_processed = process_data(\n",
    "    val_data, \n",
    "    coauthor_matrix=ca_matrix, \n",
    "    keyword_matrix=kw_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 38466\n",
      "Features per instance: 113\n",
      "Number of validation instances: 9534\n",
      "Features per instance: 113\n"
     ]
    }
   ],
   "source": [
    "# separate into features and labels\n",
    "X_train = [data[:-1] for data in train_data_processed]\n",
    "y_train = [data[-1] for data in train_data_processed]\n",
    "\n",
    "X_val = [data[:-1] for data in val_data_processed]\n",
    "y_val = [data[-1] for data in val_data_processed]\n",
    "\n",
    "print(\"Number of training instances:\", int(len(X_train)==len(y_train))*len(X_train))\n",
    "print(\"Features per instance:\", len(X_train[0]))\n",
    "print(\"Number of validation instances:\", int(len(X_val)==len(y_val))*len(X_val))\n",
    "print(\"Features per instance:\", len(X_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training: 1.6204843521118164 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# create a SVM classifier and train on training data (takes too long at the moment)\n",
    "#clf = SVC(C=0.1, gamma='auto', random_state=RANDOM_STATE)\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "# create a nB classifier and train on training data\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken for training:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities (untested at the moment because training takes too long)\n",
    "y_preds = clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_preds(instance_probs, target):\n",
    "    probs = zip(range(N_AUTHORS), instance_probs)\n",
    "    probs = sorted(probs, key=lambda x: x[1], reverse=True)\n",
    "    front = probs.pop(0)\n",
    "    output = []\n",
    "    while front[0] != target and probs:\n",
    "        output.append(front)\n",
    "        front = probs.pop(0)\n",
    "    output.append(front)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000, 486, 209, 119, 110, 336, 135, 82, 189, 476, 492, 390, 146, 474, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 486, 244, 244, 244, 244, 244, 244, 244, 244, 244]\n",
      "244\n",
      "1 2302\n"
     ]
    }
   ],
   "source": [
    "print(X_val[0])\n",
    "print(y_val[0])\n",
    "analyse_preds(y_preds[0], y_val[0])\n",
    "\n",
    "lens = []\n",
    "for i in range(len(y_preds)):\n",
    "    lens.append(len(analyse_preds(y_preds[i], y_val[i])))\n",
    "print(min(lens), max(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{250: 11,\n",
       " 23: 31,\n",
       " 2251: 2,\n",
       " 1639: 6,\n",
       " 859: 2,\n",
       " 1738: 4,\n",
       " 803: 4,\n",
       " 2143: 3,\n",
       " 1763: 4,\n",
       " 564: 5,\n",
       " 1470: 4,\n",
       " 991: 2,\n",
       " 2228: 4,\n",
       " 2265: 6,\n",
       " 1770: 3,\n",
       " 1975: 3,\n",
       " 68: 15,\n",
       " 2115: 8,\n",
       " 1069: 3,\n",
       " 1484: 5,\n",
       " 213: 8,\n",
       " 1076: 5,\n",
       " 209: 4,\n",
       " 2018: 6,\n",
       " 141: 14,\n",
       " 57: 14,\n",
       " 1899: 5,\n",
       " 76: 11,\n",
       " 188: 10,\n",
       " 1378: 2,\n",
       " 49: 10,\n",
       " 1904: 7,\n",
       " 84: 20,\n",
       " 63: 14,\n",
       " 10: 25,\n",
       " 1542: 3,\n",
       " 365: 5,\n",
       " 562: 5,\n",
       " 113: 9,\n",
       " 161: 12,\n",
       " 356: 4,\n",
       " 2: 35,\n",
       " 25: 20,\n",
       " 760: 5,\n",
       " 2019: 10,\n",
       " 702: 5,\n",
       " 695: 1,\n",
       " 2059: 4,\n",
       " 2284: 7,\n",
       " 30: 19,\n",
       " 477: 3,\n",
       " 906: 3,\n",
       " 355: 5,\n",
       " 85: 13,\n",
       " 496: 5,\n",
       " 540: 4,\n",
       " 275: 5,\n",
       " 1237: 2,\n",
       " 1528: 4,\n",
       " 22: 28,\n",
       " 88: 11,\n",
       " 246: 9,\n",
       " 1867: 2,\n",
       " 59: 11,\n",
       " 258: 9,\n",
       " 1660: 4,\n",
       " 827: 2,\n",
       " 1417: 2,\n",
       " 542: 2,\n",
       " 2255: 6,\n",
       " 1252: 3,\n",
       " 599: 5,\n",
       " 249: 7,\n",
       " 33: 15,\n",
       " 1766: 6,\n",
       " 102: 5,\n",
       " 367: 6,\n",
       " 288: 5,\n",
       " 640: 8,\n",
       " 1995: 2,\n",
       " 1787: 5,\n",
       " 584: 2,\n",
       " 350: 3,\n",
       " 861: 3,\n",
       " 571: 3,\n",
       " 544: 6,\n",
       " 1841: 3,\n",
       " 34: 22,\n",
       " 2206: 2,\n",
       " 697: 6,\n",
       " 2036: 5,\n",
       " 104: 8,\n",
       " 1342: 4,\n",
       " 1891: 3,\n",
       " 64: 21,\n",
       " 1196: 5,\n",
       " 1132: 8,\n",
       " 1155: 2,\n",
       " 55: 18,\n",
       " 254: 15,\n",
       " 227: 3,\n",
       " 324: 5,\n",
       " 208: 8,\n",
       " 2279: 3,\n",
       " 1384: 3,\n",
       " 327: 10,\n",
       " 1070: 2,\n",
       " 1478: 6,\n",
       " 136: 13,\n",
       " 1055: 4,\n",
       " 556: 3,\n",
       " 998: 6,\n",
       " 2047: 3,\n",
       " 289: 7,\n",
       " 98: 9,\n",
       " 132: 6,\n",
       " 1878: 7,\n",
       " 994: 4,\n",
       " 66: 12,\n",
       " 583: 3,\n",
       " 1675: 6,\n",
       " 1549: 6,\n",
       " 945: 3,\n",
       " 677: 4,\n",
       " 26: 23,\n",
       " 2008: 2,\n",
       " 96: 9,\n",
       " 2188: 6,\n",
       " 418: 8,\n",
       " 149: 6,\n",
       " 456: 2,\n",
       " 623: 3,\n",
       " 1037: 3,\n",
       " 1595: 4,\n",
       " 281: 8,\n",
       " 546: 4,\n",
       " 1184: 7,\n",
       " 1582: 5,\n",
       " 119: 6,\n",
       " 1176: 4,\n",
       " 1454: 1,\n",
       " 2232: 7,\n",
       " 1653: 4,\n",
       " 1408: 2,\n",
       " 1447: 6,\n",
       " 1071: 1,\n",
       " 1577: 3,\n",
       " 1305: 3,\n",
       " 1940: 3,\n",
       " 434: 2,\n",
       " 1013: 4,\n",
       " 1095: 1,\n",
       " 170: 4,\n",
       " 643: 5,\n",
       " 1981: 3,\n",
       " 1513: 3,\n",
       " 1290: 2,\n",
       " 120: 16,\n",
       " 1437: 2,\n",
       " 2283: 5,\n",
       " 80: 11,\n",
       " 58: 17,\n",
       " 2131: 3,\n",
       " 44: 16,\n",
       " 1292: 3,\n",
       " 308: 3,\n",
       " 169: 10,\n",
       " 788: 4,\n",
       " 724: 2,\n",
       " 503: 4,\n",
       " 303: 3,\n",
       " 1072: 6,\n",
       " 118: 8,\n",
       " 61: 17,\n",
       " 54: 16,\n",
       " 1882: 5,\n",
       " 1923: 3,\n",
       " 15: 12,\n",
       " 1705: 4,\n",
       " 160: 9,\n",
       " 1491: 5,\n",
       " 338: 6,\n",
       " 832: 2,\n",
       " 238: 7,\n",
       " 2099: 4,\n",
       " 1968: 2,\n",
       " 32: 21,\n",
       " 631: 4,\n",
       " 513: 2,\n",
       " 1583: 4,\n",
       " 1214: 5,\n",
       " 1751: 4,\n",
       " 81: 16,\n",
       " 28: 15,\n",
       " 21: 21,\n",
       " 1474: 2,\n",
       " 594: 3,\n",
       " 1688: 4,\n",
       " 212: 6,\n",
       " 502: 4,\n",
       " 737: 7,\n",
       " 146: 13,\n",
       " 1618: 4,\n",
       " 1320: 6,\n",
       " 218: 11,\n",
       " 1967: 7,\n",
       " 9: 20,\n",
       " 5: 25,\n",
       " 1921: 2,\n",
       " 1731: 4,\n",
       " 2083: 7,\n",
       " 19: 24,\n",
       " 2276: 5,\n",
       " 745: 4,\n",
       " 2140: 3,\n",
       " 20: 30,\n",
       " 24: 23,\n",
       " 1315: 6,\n",
       " 1159: 4,\n",
       " 1412: 3,\n",
       " 60: 12,\n",
       " 1815: 6,\n",
       " 51: 20,\n",
       " 836: 4,\n",
       " 1847: 6,\n",
       " 43: 14,\n",
       " 1178: 3,\n",
       " 2191: 6,\n",
       " 320: 8,\n",
       " 630: 8,\n",
       " 1029: 5,\n",
       " 1597: 5,\n",
       " 580: 5,\n",
       " 1745: 2,\n",
       " 351: 5,\n",
       " 138: 7,\n",
       " 1767: 3,\n",
       " 270: 5,\n",
       " 924: 4,\n",
       " 645: 6,\n",
       " 18: 20,\n",
       " 1817: 3,\n",
       " 966: 2,\n",
       " 1790: 4,\n",
       " 87: 8,\n",
       " 94: 10,\n",
       " 16: 21,\n",
       " 1889: 6,\n",
       " 1062: 7,\n",
       " 2186: 4,\n",
       " 1650: 5,\n",
       " 2050: 2,\n",
       " 36: 18,\n",
       " 658: 5,\n",
       " 1125: 3,\n",
       " 2003: 7,\n",
       " 397: 3,\n",
       " 108: 17,\n",
       " 1866: 2,\n",
       " 1146: 3,\n",
       " 501: 2,\n",
       " 83: 11,\n",
       " 1173: 4,\n",
       " 384: 6,\n",
       " 551: 5,\n",
       " 286: 5,\n",
       " 2159: 6,\n",
       " 121: 13,\n",
       " 1294: 5,\n",
       " 1128: 7,\n",
       " 1926: 6,\n",
       " 1163: 9,\n",
       " 53: 13,\n",
       " 1649: 4,\n",
       " 143: 11,\n",
       " 1806: 3,\n",
       " 1831: 2,\n",
       " 2147: 4,\n",
       " 294: 7,\n",
       " 333: 10,\n",
       " 1489: 3,\n",
       " 279: 6,\n",
       " 1994: 3,\n",
       " 328: 4,\n",
       " 181: 5,\n",
       " 871: 3,\n",
       " 1872: 5,\n",
       " 713: 2,\n",
       " 1123: 7,\n",
       " 4: 26,\n",
       " 117: 9,\n",
       " 1369: 4,\n",
       " 1902: 4,\n",
       " 163: 10,\n",
       " 2032: 1,\n",
       " 1313: 5,\n",
       " 882: 1,\n",
       " 557: 3,\n",
       " 937: 4,\n",
       " 166: 9,\n",
       " 1302: 5,\n",
       " 1972: 2,\n",
       " 245: 12,\n",
       " 1836: 2,\n",
       " 1485: 4,\n",
       " 1084: 3,\n",
       " 297: 8,\n",
       " 2148: 6,\n",
       " 1610: 4,\n",
       " 1297: 7,\n",
       " 2042: 4,\n",
       " 696: 4,\n",
       " 1: 51,\n",
       " 2030: 8,\n",
       " 1334: 5,\n",
       " 1512: 7,\n",
       " 475: 2,\n",
       " 1285: 4,\n",
       " 388: 6,\n",
       " 1337: 5,\n",
       " 260: 6,\n",
       " 219: 8,\n",
       " 1497: 8,\n",
       " 1587: 2,\n",
       " 1503: 4,\n",
       " 207: 5,\n",
       " 312: 6,\n",
       " 232: 8,\n",
       " 2233: 5,\n",
       " 1801: 4,\n",
       " 1441: 4,\n",
       " 14: 19,\n",
       " 815: 3,\n",
       " 740: 6,\n",
       " 1781: 1,\n",
       " 507: 2,\n",
       " 199: 7,\n",
       " 1756: 2,\n",
       " 2034: 5,\n",
       " 1152: 4,\n",
       " 1312: 2,\n",
       " 252: 3,\n",
       " 1913: 1,\n",
       " 40: 14,\n",
       " 176: 4,\n",
       " 12: 18,\n",
       " 1104: 6,\n",
       " 670: 1,\n",
       " 2116: 5,\n",
       " 2201: 4,\n",
       " 1301: 2,\n",
       " 483: 2,\n",
       " 902: 2,\n",
       " 2216: 7,\n",
       " 274: 9,\n",
       " 2243: 5,\n",
       " 1446: 3,\n",
       " 2105: 2,\n",
       " 341: 3,\n",
       " 666: 5,\n",
       " 1973: 7,\n",
       " 180: 11,\n",
       " 2282: 8,\n",
       " 1147: 6,\n",
       " 27: 16,\n",
       " 2119: 5,\n",
       " 148: 9,\n",
       " 763: 4,\n",
       " 139: 6,\n",
       " 115: 10,\n",
       " 1839: 5,\n",
       " 11: 35,\n",
       " 73: 11,\n",
       " 1209: 4,\n",
       " 1784: 3,\n",
       " 1680: 3,\n",
       " 550: 4,\n",
       " 617: 5,\n",
       " 1158: 3,\n",
       " 2220: 4,\n",
       " 240: 6,\n",
       " 116: 6,\n",
       " 648: 7,\n",
       " 1469: 3,\n",
       " 484: 3,\n",
       " 1530: 5,\n",
       " 1044: 1,\n",
       " 72: 19,\n",
       " 1391: 5,\n",
       " 1814: 3,\n",
       " 1181: 2,\n",
       " 701: 4,\n",
       " 792: 3,\n",
       " 339: 3,\n",
       " 423: 1,\n",
       " 796: 3,\n",
       " 1969: 5,\n",
       " 638: 4,\n",
       " 1808: 3,\n",
       " 1366: 2,\n",
       " 311: 8,\n",
       " 1019: 3,\n",
       " 523: 4,\n",
       " 454: 3,\n",
       " 2132: 5,\n",
       " 56: 9,\n",
       " 69: 15,\n",
       " 1522: 5,\n",
       " 2292: 5,\n",
       " 1671: 6,\n",
       " 1045: 3,\n",
       " 1615: 4,\n",
       " 1164: 5,\n",
       " 831: 6,\n",
       " 2005: 7,\n",
       " 1716: 2,\n",
       " 921: 2,\n",
       " 678: 6,\n",
       " 1101: 3,\n",
       " 1047: 3,\n",
       " 417: 3,\n",
       " 273: 5,\n",
       " 1552: 7,\n",
       " 2297: 2,\n",
       " 1353: 4,\n",
       " 2014: 4,\n",
       " 1423: 6,\n",
       " 1863: 5,\n",
       " 1393: 5,\n",
       " 1024: 5,\n",
       " 505: 5,\n",
       " 474: 7,\n",
       " 1811: 3,\n",
       " 221: 6,\n",
       " 172: 8,\n",
       " 1007: 2,\n",
       " 211: 10,\n",
       " 1912: 7,\n",
       " 193: 6,\n",
       " 420: 10,\n",
       " 1018: 3,\n",
       " 1932: 7,\n",
       " 394: 3,\n",
       " 106: 10,\n",
       " 824: 3,\n",
       " 203: 9,\n",
       " 1544: 6,\n",
       " 2180: 8,\n",
       " 2056: 7,\n",
       " 601: 1,\n",
       " 1953: 3,\n",
       " 642: 4,\n",
       " 1380: 5,\n",
       " 1800: 4,\n",
       " 1389: 3,\n",
       " 1742: 4,\n",
       " 1061: 2,\n",
       " 253: 7,\n",
       " 2202: 3,\n",
       " 1220: 4,\n",
       " 2215: 6,\n",
       " 1406: 1,\n",
       " 3: 29,\n",
       " 494: 1,\n",
       " 1500: 2,\n",
       " 257: 5,\n",
       " 2193: 1,\n",
       " 687: 8,\n",
       " 449: 4,\n",
       " 305: 5,\n",
       " 901: 3,\n",
       " 1004: 3,\n",
       " 679: 3,\n",
       " 731: 3,\n",
       " 2055: 3,\n",
       " 458: 6,\n",
       " 1760: 5,\n",
       " 1661: 3,\n",
       " 2096: 5,\n",
       " 2175: 5,\n",
       " 847: 2,\n",
       " 242: 4,\n",
       " 736: 4,\n",
       " 92: 11,\n",
       " 239: 6,\n",
       " 234: 9,\n",
       " 1786: 3,\n",
       " 837: 7,\n",
       " 693: 2,\n",
       " 173: 5,\n",
       " 179: 10,\n",
       " 1616: 6,\n",
       " 1425: 4,\n",
       " 2209: 5,\n",
       " 1097: 5,\n",
       " 329: 4,\n",
       " 1165: 1,\n",
       " 71: 11,\n",
       " 852: 4,\n",
       " 463: 5,\n",
       " 2170: 6,\n",
       " 1531: 2,\n",
       " 892: 1,\n",
       " 561: 5,\n",
       " 664: 5,\n",
       " 2129: 5,\n",
       " 1573: 5,\n",
       " 74: 10,\n",
       " 1012: 5,\n",
       " 2113: 4,\n",
       " 31: 13,\n",
       " 809: 4,\n",
       " 1980: 4,\n",
       " 77: 10,\n",
       " 2035: 5,\n",
       " 1492: 5,\n",
       " 336: 3,\n",
       " 704: 2,\n",
       " 1819: 5,\n",
       " 717: 2,\n",
       " 1726: 3,\n",
       " 134: 6,\n",
       " 309: 4,\n",
       " 1508: 5,\n",
       " 817: 3,\n",
       " 142: 7,\n",
       " 1809: 3,\n",
       " 38: 11,\n",
       " 864: 7,\n",
       " 406: 5,\n",
       " 722: 3,\n",
       " 47: 19,\n",
       " 342: 6,\n",
       " 2017: 5,\n",
       " 1799: 4,\n",
       " 572: 3,\n",
       " 405: 12,\n",
       " 125: 10,\n",
       " 152: 8,\n",
       " 844: 3,\n",
       " 612: 3,\n",
       " 2013: 9,\n",
       " 1509: 9,\n",
       " 210: 12,\n",
       " 214: 6,\n",
       " 378: 5,\n",
       " 2178: 11,\n",
       " 962: 1,\n",
       " 1879: 5,\n",
       " 1035: 2,\n",
       " 878: 3,\n",
       " 2183: 4,\n",
       " 100: 10,\n",
       " 29: 23,\n",
       " 2107: 2,\n",
       " 1537: 3,\n",
       " 1481: 9,\n",
       " 1015: 5,\n",
       " 1039: 2,\n",
       " 187: 3,\n",
       " 229: 4,\n",
       " 133: 11,\n",
       " 70: 15,\n",
       " 175: 4,\n",
       " 1602: 5,\n",
       " 1707: 2,\n",
       " 1124: 3,\n",
       " 307: 5,\n",
       " 1385: 3,\n",
       " 1402: 2,\n",
       " 603: 5,\n",
       " 2062: 2,\n",
       " 1075: 6,\n",
       " 217: 8,\n",
       " 1665: 5,\n",
       " 430: 3,\n",
       " 97: 19,\n",
       " 2250: 5,\n",
       " 2028: 4,\n",
       " 42: 18,\n",
       " 1829: 3,\n",
       " 2207: 5,\n",
       " 2187: 12,\n",
       " 332: 6,\n",
       " 1457: 3,\n",
       " 2281: 11,\n",
       " 942: 6,\n",
       " 2146: 6,\n",
       " 472: 3,\n",
       " 938: 3,\n",
       " 1205: 3,\n",
       " 159: 6,\n",
       " 682: 3,\n",
       " 1078: 4,\n",
       " 1720: 3,\n",
       " 1496: 2,\n",
       " 1245: 2,\n",
       " 2097: 2,\n",
       " 276: 8,\n",
       " 379: 5,\n",
       " 1137: 3,\n",
       " 62: 9,\n",
       " 2049: 5,\n",
       " 2258: 5,\n",
       " 6: 31,\n",
       " 93: 17,\n",
       " 1398: 3,\n",
       " 2068: 1,\n",
       " 1268: 2,\n",
       " 268: 6,\n",
       " 1218: 5,\n",
       " 2182: 6,\n",
       " 667: 2,\n",
       " 1009: 3,\n",
       " 797: 6,\n",
       " 1319: 6,\n",
       " 691: 6,\n",
       " 197: 8,\n",
       " 848: 6,\n",
       " 114: 12,\n",
       " 1871: 3,\n",
       " 1909: 2,\n",
       " 52: 15,\n",
       " 244: 4,\n",
       " 389: 2,\n",
       " 91: 16,\n",
       " 1846: 1,\n",
       " 1401: 2,\n",
       " 835: 5,\n",
       " 806: 6,\n",
       " 216: 6,\n",
       " 225: 6,\n",
       " 834: 5,\n",
       " 488: 1,\n",
       " 86: 11,\n",
       " 970: 5,\n",
       " 2225: 6,\n",
       " 137: 5,\n",
       " 2029: 6,\n",
       " 818: 6,\n",
       " 863: 5,\n",
       " 448: 3,\n",
       " 714: 7,\n",
       " 2214: 5,\n",
       " 1533: 3,\n",
       " 144: 10,\n",
       " 2262: 5,\n",
       " 1988: 6,\n",
       " 13: 16,\n",
       " 2231: 4,\n",
       " 262: 4,\n",
       " 720: 2,\n",
       " 635: 6,\n",
       " 1931: 2,\n",
       " 1916: 6,\n",
       " 2288: 3,\n",
       " 2125: 5,\n",
       " 1303: 3,\n",
       " 67: 17,\n",
       " 1840: 4,\n",
       " 2197: 5,\n",
       " 1016: 4,\n",
       " 50: 22,\n",
       " 2031: 5,\n",
       " 315: 2,\n",
       " 155: 7,\n",
       " 2053: 7,\n",
       " 2078: 6,\n",
       " 130: 8,\n",
       " 99: 8,\n",
       " 1984: 2,\n",
       " 559: 6,\n",
       " 1257: 7,\n",
       " 167: 11,\n",
       " 728: 4,\n",
       " 8: 31,\n",
       " 1130: 7,\n",
       " 1546: 3,\n",
       " 872: 3,\n",
       " 1952: 3,\n",
       " 1623: 3,\n",
       " 490: 5,\n",
       " 1937: 2,\n",
       " 1349: 6,\n",
       " 1810: 4,\n",
       " 374: 4,\n",
       " 89: 15,\n",
       " 1099: 4,\n",
       " 353: 10,\n",
       " 1832: 2,\n",
       " 1947: 1,\n",
       " 993: 3,\n",
       " 1744: 5,\n",
       " 272: 7,\n",
       " 2252: 2,\n",
       " 1764: 2,\n",
       " 2145: 5,\n",
       " 1215: 3,\n",
       " 2026: 6,\n",
       " 1073: 7,\n",
       " 1021: 2,\n",
       " 680: 3,\n",
       " 1555: 5,\n",
       " 1946: 6,\n",
       " 2269: 3,\n",
       " 1999: 1,\n",
       " 909: 3,\n",
       " 742: 4,\n",
       " 2007: 3,\n",
       " 999: 4,\n",
       " 75: 14,\n",
       " 1664: 2,\n",
       " 443: 3,\n",
       " 1826: 5,\n",
       " 37: 22,\n",
       " 1687: 7,\n",
       " 401: 8,\n",
       " 857: 8,\n",
       " 314: 8,\n",
       " 649: 4,\n",
       " 634: 5,\n",
       " 582: 5,\n",
       " 424: 8,\n",
       " 811: 2,\n",
       " 186: 9,\n",
       " 2242: 4,\n",
       " 1905: 5,\n",
       " 560: 3,\n",
       " 1135: 6,\n",
       " 224: 5,\n",
       " 956: 3,\n",
       " 2162: 13,\n",
       " 2082: 3,\n",
       " 284: 9,\n",
       " 641: 8,\n",
       " 614: 6,\n",
       " 1521: 4,\n",
       " 482: 5,\n",
       " 1619: 4,\n",
       " 1000: 2,\n",
       " 1110: 4,\n",
       " 1235: 1,\n",
       " 887: 4,\n",
       " 376: 5,\n",
       " 1350: 1,\n",
       " 1282: 2,\n",
       " 1443: 3,\n",
       " 633: 4,\n",
       " 923: 4,\n",
       " 1876: 4,\n",
       " 1825: 4,\n",
       " 2090: 2,\n",
       " 765: 2,\n",
       " 1185: 6,\n",
       " 107: 10,\n",
       " 128: 6,\n",
       " 178: 10,\n",
       " 1195: 4,\n",
       " 721: 2,\n",
       " 1571: 2,\n",
       " 2219: 6,\n",
       " 195: 7,\n",
       " 2300: 4,\n",
       " 875: 4,\n",
       " 1038: 2,\n",
       " 1120: 2,\n",
       " 930: 4,\n",
       " 1151: 4,\n",
       " 1569: 3,\n",
       " 2128: 7,\n",
       " 382: 5,\n",
       " 830: 4,\n",
       " 933: 1,\n",
       " 2079: 7,\n",
       " 1438: 5,\n",
       " 145: 7,\n",
       " 1944: 2,\n",
       " 414: 3,\n",
       " 346: 4,\n",
       " 2020: 4,\n",
       " 206: 9,\n",
       " 1074: 3,\n",
       " 1539: 2,\n",
       " 442: 7,\n",
       " 1431: 4,\n",
       " 95: 11,\n",
       " 2022: 5,\n",
       " 719: 3,\n",
       " 1359: 5,\n",
       " 1332: 5,\n",
       " 2133: 3,\n",
       " 230: 6,\n",
       " 1723: 2,\n",
       " 1346: 2,\n",
       " 140: 12,\n",
       " 375: 3,\n",
       " 1202: 1,\n",
       " 82: 19,\n",
       " 438: 4,\n",
       " 168: 5,\n",
       " 1816: 2,\n",
       " 1511: 7,\n",
       " 1611: 5,\n",
       " 1134: 3,\n",
       " 200: 7,\n",
       " 726: 3,\n",
       " 1179: 1,\n",
       " 299: 7,\n",
       " 1962: 8,\n",
       " 78: 9,\n",
       " 439: 4,\n",
       " 1036: 6,\n",
       " 395: 5,\n",
       " 39: 13,\n",
       " 979: 1,\n",
       " 1524: 3,\n",
       " 185: 8,\n",
       " 2054: 2,\n",
       " 151: 9,\n",
       " 1053: 2,\n",
       " 1463: 2,\n",
       " 2181: 5,\n",
       " 1432: 4,\n",
       " 2238: 3,\n",
       " 1959: 5,\n",
       " 1453: 4,\n",
       " 383: 7,\n",
       " 265: 3,\n",
       " 1236: 1,\n",
       " 433: 2,\n",
       " 2213: 2,\n",
       " 606: 1,\n",
       " 1710: 3,\n",
       " 1679: 4,\n",
       " 2285: 1,\n",
       " 1052: 6,\n",
       " 709: 4,\n",
       " 2152: 1,\n",
       " 1783: 2,\n",
       " 1780: 2,\n",
       " 1341: 4,\n",
       " 2196: 4,\n",
       " 1506: 2,\n",
       " 683: 5,\n",
       " 1708: 6,\n",
       " 1133: 4,\n",
       " 202: 9,\n",
       " 783: 2,\n",
       " 1551: 2,\n",
       " 1354: 4,\n",
       " 839: 3,\n",
       " 282: 5,\n",
       " 204: 11,\n",
       " 1632: 4,\n",
       " 35: 13,\n",
       " 112: 4,\n",
       " 1281: 5,\n",
       " 2167: 1,\n",
       " 516: 3,\n",
       " 2044: 6,\n",
       " 1033: 4,\n",
       " 2256: 6,\n",
       " 1140: 8,\n",
       " 1686: 3,\n",
       " 1331: 2,\n",
       " 1658: 2,\n",
       " 549: 6,\n",
       " 1379: 3,\n",
       " 2101: 6,\n",
       " 626: 4,\n",
       " 1873: 5,\n",
       " 233: 2,\n",
       " 283: 3,\n",
       " 1217: 2,\n",
       " 326: 7,\n",
       " 317: 5,\n",
       " 1945: 2,\n",
       " 1939: 4,\n",
       " 1153: 4,\n",
       " 597: 4,\n",
       " 2208: 6,\n",
       " 2006: 8,\n",
       " 1166: 3,\n",
       " 331: 3,\n",
       " 984: 4,\n",
       " 409: 3,\n",
       " 668: 3,\n",
       " 2275: 9,\n",
       " 1970: 7,\n",
       " 593: 4,\n",
       " 1174: 3,\n",
       " 2144: 6,\n",
       " 2106: 2,\n",
       " 762: 3,\n",
       " 392: 5,\n",
       " 2236: 3,\n",
       " 1396: 4,\n",
       " 1434: 2,\n",
       " 191: 5,\n",
       " 408: 5,\n",
       " 615: 5,\n",
       " 660: 6,\n",
       " 1472: 6,\n",
       " 2204: 4,\n",
       " 1906: 6,\n",
       " 111: 10,\n",
       " 1077: 4,\n",
       " 789: 3,\n",
       " 632: 7,\n",
       " 1336: 2,\n",
       " 158: 2,\n",
       " 2226: 2,\n",
       " 124: 8,\n",
       " 45: 20,\n",
       " 1600: 4,\n",
       " 162: 10,\n",
       " 986: 6,\n",
       " 2268: 4,\n",
       " 1017: 1,\n",
       " 958: 2,\n",
       " 2264: 8,\n",
       " 357: 4,\n",
       " 1224: 1,\n",
       " 2002: 5,\n",
       " 1883: 5,\n",
       " 1250: 5,\n",
       " 587: 3,\n",
       " 1860: 7,\n",
       " 126: 8,\n",
       " 1798: 7,\n",
       " 364: 5,\n",
       " 154: 9,\n",
       " 1005: 2,\n",
       " 1851: 3,\n",
       " 1942: 2,\n",
       " 65: 13,\n",
       " 101: 7,\n",
       " 2095: 6,\n",
       " 637: 4,\n",
       " 547: 4,\n",
       " 1270: 3,\n",
       " 613: 5,\n",
       " 2015: 1,\n",
       " 919: 4,\n",
       " 255: 9,\n",
       " 608: 2,\n",
       " 1694: 1,\n",
       " 2179: 5,\n",
       " 2172: 6,\n",
       " 2246: 3,\n",
       " 164: 7,\n",
       " 1100: 6,\n",
       " 2130: 4,\n",
       " 509: 3,\n",
       " 1452: 7,\n",
       " 674: 2,\n",
       " 1771: 4,\n",
       " 2280: 2,\n",
       " 856: 4,\n",
       " 2009: 5,\n",
       " 934: 4,\n",
       " 459: 7,\n",
       " 2294: 3,\n",
       " 435: 3,\n",
       " 1997: 5,\n",
       " 1822: 1,\n",
       " 344: 3,\n",
       " 1762: 3,\n",
       " 536: 2,\n",
       " 1793: 9,\n",
       " 537: 2,\n",
       " 2127: 3,\n",
       " 1631: 6,\n",
       " 1131: 3,\n",
       " 1640: 4,\n",
       " 2001: 6,\n",
       " 237: 8,\n",
       " 1917: 1,\n",
       " 7: 20,\n",
       " 291: 6,\n",
       " 602: 5,\n",
       " 1621: 5,\n",
       " 1229: 3,\n",
       " 156: 12,\n",
       " 1527: 4,\n",
       " 795: 7,\n",
       " 805: 4,\n",
       " 396: 4,\n",
       " 1828: 3,\n",
       " 1734: 2,\n",
       " 293: 8,\n",
       " 1118: 4,\n",
       " 296: 7,\n",
       " 1541: 3,\n",
       " 1375: 3,\n",
       " 215: 7,\n",
       " 1525: 3,\n",
       " 189: 6,\n",
       " 533: 3,\n",
       " 2108: 5,\n",
       " ...}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_counts = {}\n",
    "for ln in lens:\n",
    "    if ln not in len_counts:\n",
    "        len_counts[ln] = 0\n",
    "    len_counts[ln] += 1\n",
    "\n",
    "len_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 148 1.0\n",
      "502 240 1.0\n",
      "1017 693 1.0\n",
      "1041 333 1.0\n",
      "1124 162 1.0\n",
      "1195 10 1.0\n",
      "1641 1664 0.9999990490618959\n",
      "1894 59 0.9993737096793283\n",
      "1907 603 1.0\n",
      "2144 35 1.0\n",
      "2167 398 1.0\n",
      "2240 1384 1.0\n",
      "2421 1563 1.0\n",
      "2431 86 1.0\n",
      "2518 0 1.0\n",
      "2542 450 1.0\n",
      "2627 603 1.0\n",
      "2688 1798 1.0\n",
      "2845 39 1.0\n",
      "2949 577 1.0\n",
      "3239 1106 0.9999999999708962\n",
      "3294 1092 1.0\n",
      "3320 49 0.5526835090396222\n",
      "3501 248 0.9948707293924562\n",
      "3649 143 0.9995850563229302\n",
      "3680 241 0.9974779807388469\n",
      "3857 1560 0.9999999963329174\n",
      "4133 2026 1.0\n",
      "5103 0 1.0\n",
      "5424 1067 0.9999998292478413\n",
      "5582 1175 0.7510491130081105\n",
      "5588 1188 0.9999997296545554\n",
      "5898 1040 0.6464789288188814\n",
      "5959 649 1.0\n",
      "5963 1734 0.9999846479636931\n",
      "6172 761 1.0\n",
      "6173 1618 1.0\n",
      "6482 710 1.0\n",
      "6551 53 1.0\n",
      "7218 2009 1.0\n",
      "7514 790 1.0\n",
      "7702 159 1.0\n",
      "8322 591 0.16166736688936528\n",
      "8349 1745 1.0\n",
      "8401 307 0.9018379605315594\n",
      "8601 170 1.0\n",
      "8659 0 1.0\n",
      "8689 171 1.0\n",
      "8897 106 0.9801004246716898\n",
      "8985 3 1.0\n",
      "9232 467 1.0\n",
      "9400 323 1.0\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_preds)):\n",
    "    target = y_val[i]\n",
    "    if y_preds[i][target] > 0.1:\n",
    "        print(i, target, y_preds[i][target])\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of authors for any one paper: 9\n",
      "Max number of keywords for any one paper: 103\n",
      "Number of training instances: 48000\n",
      "Features per instance: 113\n",
      "Number of validation instances: 2000\n",
      "Features per instance: 113\n",
      "Number of predictions: 2000\n"
     ]
    }
   ],
   "source": [
    "# find the max number of authors/keywords for any one paper in the data set\n",
    "author_counts = []\n",
    "keyword_counts = []\n",
    "for key in train_data:\n",
    "    author_counts.append(len(data[key]['author']))\n",
    "    keyword_counts.append(len(data[key]['keywords']))\n",
    "\n",
    "max_authors = max(author_counts)\n",
    "max_keywords = max(keyword_counts)\n",
    "print(\"Max number of authors for any one paper:\", max_authors)\n",
    "print(\"Max number of keywords for any one paper:\", max_keywords)\n",
    "\n",
    "# get required matrices\n",
    "ca_matrix = get_coauthor_matrix(data)\n",
    "kw_matrix = get_keyword_matrix(data)\n",
    "# process data\n",
    "data_processed = process_data(\n",
    "    data, \n",
    "    coauthor_matrix=ca_matrix, \n",
    "    keyword_matrix=kw_matrix\n",
    ")\n",
    "\n",
    "test_data_processed = process_data_test(\n",
    "    test_data, \n",
    "    coauthor_matrix=ca_matrix, \n",
    "    keyword_matrix=kw_matrix\n",
    ")\n",
    "\n",
    "# separate into features and labels\n",
    "X_train = [data[:-1] for data in data_processed]\n",
    "y_train = [data[-1] for data in data_processed]\n",
    "\n",
    "X_test = [data[:-1] for data in test_data_processed]\n",
    "y_test = [data[-1] for data in test_data_processed]\n",
    "\n",
    "print(\"Number of training instances:\", int(len(X_train)==len(y_train))*len(X_train))\n",
    "print(\"Features per instance:\", len(X_train[0]))\n",
    "print(\"Number of validation instances:\", int(len(X_test)==len(y_test))*len(X_test))\n",
    "print(\"Features per instance:\", len(X_val[0]))\n",
    "\n",
    "# create a nB classifier and train on training data\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "# predic\n",
    "y_preds = clf.predict_proba(X_test)\n",
    "print(\"Number of predictions:\", len(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract probabilities\n",
    "output = []\n",
    "for i in range(len(y_preds)):\n",
    "    target = y_val[i]\n",
    "    output.append((i, y_preds[i][target]))\n",
    "\n",
    "# write to file\n",
    "f = open(\"predictions.csv\", \"w\")\n",
    "f.write(\"Id,Predicted\\n\")\n",
    "for i, prob in output:\n",
    "    f.write(str(i) + \",\" + str(prob) + \"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
